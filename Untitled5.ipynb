{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMhmtzkRWLGkBjisjLteQQl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import requests as rq\n","from bs4 import BeautifulSoup as bs"],"metadata":{"id":"-QJQOBED60-k","executionInfo":{"status":"ok","timestamp":1680595696859,"user_tz":-420,"elapsed":3,"user":{"displayName":"Toàn","userId":"18075492819825120261"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["r = rq.get(\"https://www.facebook.com/Paimoncutee/photos/?ref=page_internal\")\n","soup = bs(r.content,\"html.parser\")\n","wrapper = soup.find('body')\n","images = wrapper.find_all('img')\n","for image in images:\n","  imgData = image['src']\n","  print(image['src'])"],"metadata":{"id":"GJ7M8B3f7BiN","executionInfo":{"status":"ok","timestamp":1680595757840,"user_tz":-420,"elapsed":320,"user":{"displayName":"Toàn","userId":"18075492819825120261"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["while (index <=10) :\n","  soup = bs(r.content,\"html.parser\")\n","  titles = soup.find_all('div',class_=\"x1n2onr6\")\n","  print(soup)\n","  index +=1\n","  if(index >=10) : break\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-XmVo5Bk7BYV","executionInfo":{"status":"ok","timestamp":1680589544847,"user_tz":-420,"elapsed":1681,"user":{"displayName":"Toàn","userId":"18075492819825120261"}},"outputId":"fa36addc-d150-41be-da48-4d9e8723d579"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" titles = soup.find_all('h2',class_=\"feature-box__content--title vnn-title\")\n","  links = [link.find('a').attrs[\"href\"] for link in titles]\n","  for link in links:\n","    news = rq.get(link)\n","    print(link)\n","    soup = bs(news.content,\"html.parser\")\n","    noidung = \"\"\n","    theloai = \"\"\n","    try :\n","      divtt = soup.find('div',class_=\"bread-crumb-detail\") \n","      div = soup.find('div',class_=\"maincontent\")\n","      title = soup.find('h1',class_=\"content-detail-title\").text\n","      mota = soup.find('h2',class_=\"content-detail-sapo\").text\n","      theloai1 = divtt.find_all('a')\n","      for i in (theloai1):\n","                theloai = i.text\n","      noidung1 = div.find_all('p')\n","      for i in (noidung1):\n","                noidung += (i.text  + \" \")\n","      collections_data = {\n","          'Tiêu đề':title,\n","          'Mô tả':mota.strip(),\n","          'Thể loại':theloai.strip(),\n","          'Nội dung':noidung\n","      }\n","      data.append(collections_data)\n","      print(30*\"*\")\n","      print(\"Tiêu đề:\",title)\n","    except: \n","      continue\n","  df = pd.DataFrame(data)\n","df.to_excel('data1.xlsx')"],"metadata":{"id":"VNHp9aTC8DbL"},"execution_count":null,"outputs":[]}]}